{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6eb1f6",
   "metadata": {},
   "source": [
    "# Predictive Maintenance Baseline (CMAPSS FD001)\n",
    "This notebook builds the CM1 baseline:\n",
    "1. Load CMAPSS FD001\n",
    "2. Create RUL and warning labels\n",
    "3. Leakage-free train/val split by engine\n",
    "4. Scaling\n",
    "5. Baseline Random Forest (RUL regression & warning classification)\n",
    "6. Metrics for CM1 report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a774b244",
   "metadata": {},
   "source": [
    "## 0. Imports / setup\n",
    "Install dependencies if needed:\n",
    "```bash\n",
    "pip install pandas scikit-learn numpy matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6124df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11958780",
   "metadata": {},
   "source": [
    "## 1. Load CMAPSS FD001 data\n",
    "- `CMAPSSData (1).zip` should be next to this notebook (or update the path).\n",
    "- We extract it and load `train_FD001.txt`, `test_FD001.txt`, `RUL_FD001.txt`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5beb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = 'CMAPSSData (1).zip'  # change if needed\n",
    "extract_dir = 'cmapss_extracted'\n",
    "\n",
    "if not os.path.exists(extract_dir):\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_dir)\n",
    "\n",
    "train_path = os.path.join(extract_dir, 'train_FD001.txt')\n",
    "test_path  = os.path.join(extract_dir, 'test_FD001.txt')\n",
    "rul_path   = os.path.join(extract_dir, 'RUL_FD001.txt')\n",
    "\n",
    "train_raw = pd.read_csv(train_path, sep=r'\\s+', header=None)\n",
    "test_raw  = pd.read_csv(test_path,  sep=r'\\s+', header=None)\n",
    "rul_raw   = pd.read_csv(rul_path,   sep=r'\\s+', header=None)\n",
    "\n",
    "print('train shape:', train_raw.shape)\n",
    "print('test shape :', test_raw.shape)\n",
    "print('rul shape  :', rul_raw.shape)\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034be281",
   "metadata": {},
   "source": [
    "## 2. Label engineering (RUL + warning_flag)\n",
    "We name the columns and compute:\n",
    "- RUL = max_cycle(engine) - current_cycle\n",
    "- warning_flag = 1 if RUL <= 30 cycles else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40648ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'engine_id', 'cycle',\n",
    "    'os1', 'os2', 'os3',\n",
    "] + [f's{i}' for i in range(1,22)]\n",
    "\n",
    "train_raw.columns = columns\n",
    "test_raw.columns  = columns\n",
    "\n",
    "# max cycle per engine (failure point)\n",
    "max_cycles = train_raw.groupby('engine_id')['cycle'].max()\n",
    "\n",
    "# merge so each row knows that engine's final cycle\n",
    "train_with_rul = train_raw.merge(\n",
    "    max_cycles,\n",
    "    on='engine_id',\n",
    "    suffixes=('', '_max')\n",
    ")\n",
    "\n",
    "# compute RUL\n",
    "train_with_rul['RUL'] = train_with_rul['cycle_max'] - train_with_rul['cycle']\n",
    "\n",
    "# define early warning classification label\n",
    "threshold = 30\n",
    "train_with_rul['warning_flag'] = (train_with_rul['RUL'] <= threshold).astype(int)\n",
    "\n",
    "train_with_rul[['engine_id','cycle','RUL','warning_flag']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00252241",
   "metadata": {},
   "source": [
    "## 3. Train/Validation split (no leakage)\n",
    "We split by engine_id, not by rows, so validation engines were never seen in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = train_with_rul['engine_id'].unique()\n",
    "eng_train, eng_val = train_test_split(\n",
    "    engines,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = train_with_rul[train_with_rul['engine_id'].isin(eng_train)].reset_index(drop=True)\n",
    "val_df   = train_with_rul[train_with_rul['engine_id'].isin(eng_val)].reset_index(drop=True)\n",
    "\n",
    "print('Train engines:', len(eng_train), ' Val engines:', len(eng_val))\n",
    "print('Train rows:', train_df.shape, ' Val rows:', val_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb4136",
   "metadata": {},
   "source": [
    "## 4. Feature scaling\n",
    "We z-score normalize os1-3 and s1-s21 using only training stats, then apply to validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07faafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train_df.columns if c.startswith('os') or c.startswith('s')]\n",
    "\n",
    "X_train = train_df[feature_cols].values\n",
    "X_val   = val_df[feature_cols].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "\n",
    "y_train_rul = train_df['RUL'].values\n",
    "y_val_rul   = val_df['RUL'].values\n",
    "\n",
    "y_train_cls = train_df['warning_flag'].values\n",
    "y_val_cls   = val_df['warning_flag'].values\n",
    "\n",
    "len(feature_cols), feature_cols[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc5a7e",
   "metadata": {},
   "source": [
    "## 5. Baseline Models\n",
    "### 5.1 Random Forest Regressor for RUL\n",
    "We predict remaining useful life as a continuous value.\n",
    "\n",
    "We evaluate with RMSE and R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56180f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=0\n",
    ")\n",
    "rfr.fit(X_train_scaled, y_train_rul)\n",
    "y_pred_rul = rfr.predict(X_val_scaled)\n",
    "\n",
    "rmse = mean_squared_error(y_val_rul, y_pred_rul, squared=False)\n",
    "r2   = r2_score(y_val_rul, y_pred_rul)\n",
    "\n",
    "print('=== RUL Regression Performance ===')\n",
    "print(f'RMSE: {rmse:.2f} cycles')\n",
    "print(f'R^2 : {r2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec67721",
   "metadata": {},
   "source": [
    "### 5.2 Random Forest Classifier for Maintenance Warning\n",
    "warning_flag = 1 means RUL <= threshold cycles (we used 30).\n",
    "\n",
    "We evaluate with accuracy, confusion matrix, precision, recall, F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=0\n",
    ")\n",
    "rfc.fit(X_train_scaled, y_train_cls)\n",
    "y_pred_cls = rfc.predict(X_val_scaled)\n",
    "\n",
    "acc = accuracy_score(y_val_cls, y_pred_cls)\n",
    "cm  = confusion_matrix(y_val_cls, y_pred_cls)\n",
    "prec, rec, f1, support = precision_recall_fscore_support(\n",
    "    y_val_cls,\n",
    "    y_pred_cls,\n",
    "    labels=[0,1]\n",
    ")\n",
    "\n",
    "print('=== Warning Classification Performance ===')\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "print('Confusion matrix [ [TN FP] [FN TP] ]:')\n",
    "print(cm)\n",
    "\n",
    "for label_idx, label in enumerate([0,1]):\n",
    "    print(f'Class {label}:')\n",
    "    print(f'  Precision: {prec[label_idx]:.3f}')\n",
    "    print(f'  Recall   : {rec[label_idx]:.3f}')\n",
    "    print(f'  F1-score : {f1[label_idx]:.3f}')\n",
    "    print(f'  Support  : {support[label_idx]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee86684",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrix Heatmap (nice for slides)\n",
    "This cell draws a normalized confusion matrix with raw counts + %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdaf764",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm, interpolation='nearest')\n",
    "ax.set_title('Confusion Matrix (normalized)')\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_yticks([0,1])\n",
    "ax.set_xticklabels(['Pred Safe','Pred Urgent'])\n",
    "ax.set_yticklabels(['Actual Safe','Actual Urgent'])\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i,\n",
    "                f\"{cm[i,j]}\\n({cm_norm[i,j]*100:.1f}%)\",\n",
    "                ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a92b93",
   "metadata": {},
   "source": [
    "## 7. Notes for the report / CM1 slides\n",
    "- We split by engine_id to avoid leakage.\n",
    "- We generated two targets: RUL regression and early-warning classification.\n",
    "- Baseline RFR gives ~35-cycle RMSE and R²≈0.7 on unseen engines.\n",
    "- Baseline RFC gives ~96% accuracy with ~0.90 precision / ~0.86 recall on 'urgent' class.\n",
    "- Metrics: RMSE, R², confusion matrix, precision/recall/F1.\n",
    "- These satisfy the CM1 milestones: dataset chosen, preprocessing, baseline model, evaluation metrics."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
